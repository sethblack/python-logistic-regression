import math
import matplotlib.pyplot as plt


def sigmoid(x):
    return 1. / (1. + 2.7182818284590452 ** (-x))


def output(m, x, b):
    return (m * x) + b


def cross_entropy(predicted, actual):
    L = ((-actual) * math.log(predicted))
    R = ((-actual) * math.log(-predicted))
    return  L - R


def main():
    train = [
        (0.8229549091140445, 1),
        (0.9029578256506636, 1),
        (0.6284086121173734, 1),
        (0.8414377324739029, 1),
        (0.7688668998058922, 1),
        (0.571027664775652, 1),
        (0.5808736238760608, 1),
        (0.7802187084403386, 1),
        (0.9965609287262198, 1),
        (0.964308929685514, 1),
        (0.9255454554876423, 1),
        (0.5037839297905295, 1),
        (0.5969876505732685, 1),
        (0.599545569401825, 1),
        (0.983320536809477, 1),
        (0.894147929374691, 1),
        (0.5522534451158421, 1),
        (0.7223666610306383, 1),
        (0.7900962585584712, 1),
        (0.968107613136047, 1),
        (0.8750838214274139, 1),
        (0.840093709374788, 1),
        (0.5734729688434795, 1),
        (0.5402611276515709, 1),
        (0.6694419554536277, 1),
        (0.5313870019656717, 1),
        (0.7020230908123286, 1),
        (0.7561294082282769, 1),
        (0.6565432987235208, 1),
        (0.7234469045941269, 1),
        (0.5661886753934928, 1),
        (0.9340796283971411, 1),
        (0.1615580336621683, 0),
        (0.18947968429102208, 0),
        (0.1864170924899179, 0),
        (0.1932218438410102, 0),
        (0.025923292438184198, 0),
        (0.4140607568264771, 0),
        (0.18563751968498188, 0),
        (0.3087652107923181, 0),
        (0.48375242778560934, 0),
        (0.4564704984676808, 0),
        (0.03145282662778748, 0),
        (0.20078206102640017, 0),
        (0.43811158821182666, 0),
        (0.34939740779767575, 0),
        (0.12568566416065163, 0),
        (0.39817279880629153, 0),
        (0.11363080723389613, 0),
        (0.36443792816411846, 0),
        (0.20047841259488036, 0),
        (0.2894453805660906, 0),
        (0.4091848009160222, 0),
        (0.026783645374768683, 0),
        (0.32527185822819926, 0),
        (0.34463653854158255, 0),
        (0.2161852317585733, 0),
        (0.1373683979362827, 0),
        (0.3234825819542676, 0),
        (0.4380229465062678, 0),
        (0.22275973752801553, 0),
        (0.39541701328167683, 0),
        (0.14072128019826663, 0),
        (0.0020308743577306387, 0),
        (0.49040998594357416, 0),
        (0.48436183158805796, 0),
        (0.3462936430135042, 0),
        (0.17496482256286722, 0),
        (0.46936640528079393, 0),
    ]

    test = [
        (.36720942340220348903, 0),
        (.96637528015531858223, 1),
        (.2945647049846768234022, 0),
        (.101783645378017220348, 0),
        (.798072128012340220348, 1),
    ]

    validate = [

    ]

    m = 0.
    b = 0.
    learning_rate = 0.001

    X, Y = zip(*train)

    plt.scatter(X, Y, c=Y, cmap='rainbow')

    for epoch in range(2):
        print(f'epoch {epoch}')

        for t in train:
            x = t[0]
            predicted = sigmoid(output(m, x, b))
            actual = t[1]


            delta_m = x * (predicted - actual)
            delta_b = predicted - actual

            m = m - (delta_m * learning_rate)
            b = b - (delta_b * learning_rate)

            #print(predicted, actual, cost, m, b, delta_m, delta_b)

        num_correct = 0.

        for t in test:
            predicted = sigmoid(output(m, x, b))

            if predicted == t[1]:
                num_correct += 1.

        print('accuracy', num_correct / len(test), m, b)

    plt.show()

main()